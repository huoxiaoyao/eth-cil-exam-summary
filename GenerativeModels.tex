% !TEX root = Main.tex
\section{Variational autoencoder}
Assumptions: dataset $\mathbf{X}:= \{x^{(i)}\}_{i=1}^N$ generated from hidden $\mathbf{z} \in \mathbb{R}^J$ by sampling $\mathbf{z}^{(i)}$ from true prior $p_{\theta^*}(\mathbf{z})$ and then drawing $\mathbf{x}^{(i)}$ from $p_{\theta^*}(\mathbf{x} | \mathbf{z})$. $q_\Phi(\mathbf{z}|\mathbf{x}^{(i)})$ is variational approx of true posterior $p_{\theta^*}(\mathbf{z} | \mathbf{x})$ \textbf{elbo}: $\sum_{i=1}^N\log{p_\theta(x^{(i)})}=\mathbb{E}_{z \sim q_\Phi(\mathbf{z}|\mathbf{x}^{(i)})}[\log{p_\theta(x^{(i)})}] = \mathbb{E}_z[\log{\frac{p_{\theta}(\mathbf{x}^{(i)} | \mathbf{z})p_{\theta}(\mathbf{z})}{p_{\theta}(\mathbf{z} | \mathbf{x}^{(i)})}\frac{q_\Phi(\mathbf{z}|\mathbf{x}^{(i)})}{q_\Phi(\mathbf{z}|\mathbf{x}^{(i)})}}] = \mathbb{E}_z[\log{p_{\theta}(\mathbf{x}^{(i)}|z)}] - \mathbb{E}_z[\log{\frac{q_\Phi(\mathbf{z}|\mathbf{x}^{(i)})}{p_{\theta}(\mathbf{z})}}] + \mathbb{E}_z[\log{\frac{q_\Phi(\mathbf{z}|\mathbf{x}^{(i)})}{p_{\theta}(\mathbf{z}|\mathbf{x}^{(i)})}}] = \mathbb{E}_z[\log{p_{\theta}(\mathbf{x}^{(i)}|z)}] - D_{KL}({q_\Phi(\mathbf{z}|\mathbf{x}^{(i)})}||{p_{\theta}(\mathbf{z})}) + D_{KL}({q_\Phi(\mathbf{z}|\mathbf{x}^{(i)})}||{p_{\theta}(\mathbf{z}|\mathbf{x}^{(i)})}) \geq \mathbb{E}_z[\log{p_{\theta}(\mathbf{x}^{(i)}|z)}] - D_{KL}({q_\Phi(\mathbf{z}|\mathbf{x}^{(i)})}||{p_{\theta}(\mathbf{z})}) = $ \textbf{elbo}. Encoder maximizes over $\theta$, decoder $\Phi$.

\subsection*{Autoregressive Models}
\textbf{PixelCNN}: img $\mathbf{x}$, single pixel $\mathbf{x}_i$. $p(\mathbf{x}) = \prod_{i=1}^{n^2}p(\mathbf{x_i}|\mathbf{x_1}, ..., \mathbf{x_{i-1}})$
